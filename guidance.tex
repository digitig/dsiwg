%================================================================================
%       Safety Critical Systems Club - Data Safety Initiative Working Group
%================================================================================
%                       DDDD    SSSS  IIIII  W   W   GGGG
%                       D   D  S        I    W   W  G   
%                       D   D   SSS     I    W W W  G  GG
%                       D   D      S    I    WW WW  G   G
%                       DDDD   SSSS   IIIII  W   W   GGG
%================================================================================
%               Data Safety Guidance Document - LaTeX Source File
%================================================================================
%
% Description:
%   Guidance section.
%
%================================================================================
\section{Guidance (Informative)} \label{bkm:guidance}

\dsiwgSectionQuote{I wanted to separate data from programs, because data and instructions are very different.}{Ken Thompson}


\subsection{Establish Context}
\subsubsection{Interface control}\index{Interface!Organizational}
The interfaces between \index{Data!Owner}\glspl{data owner}, and indeed data ownership itself, can be much more complicated\cbstart\ for data\cbend\ than for hardware or software, where the owner can be clearly identified. Indeed, when combining items from various sources it is possible to create data for which there is not an ``owner'' in any traditional sense. In such circumstances it may be appropriate for the overall system owner to take responsibility for the collected data and, where appropriate, pass specific, formally-recorded requirements \cbstart on to\cbend\ original data suppliers. 

The \cbstart \index{Data!Owner}\glspl{data owner} or lack of data owner throughout the lifecycle\index{Lifecycle!Data} of data within the system should be identified\cbend, including where data is merged or modified through the system operation. This will \cbstart help gain a greater understanding of how data safety issues can be controlled \cbend within the assessment at a particular organizational level.

\subsubsection{\ecapitalisewords{\glsentrylong{odr}} Form}
\cbstart\autoref{bkm:assessment} presents an \gls{odr} assessment form capture a high-level perspective on the risk posed to an organization by data safety issues within a specific project. How the assessment integrates with an organization's existing risk (or safety) management processes is the responsibility of the implementing organization. Ihe form could be used to help tailor the data safety process. The following paragraphs describe the connections between the \gls{odr} and the
\acrshort{iso} 31000 \cite{citation:iso310002018risk}
standard for risk management\cbend.

Establishing the context of a risk assessment ensures that the system being considered and the scope of any assessment is well defined. This helps prevent an overrun of the assessment's boundaries and allows \cbstart which items are in or out of scope\cbend\ to be explicitly communicated to all \index{Stakeholder}\glspl{stakeholder}. In addition, it is the role of this activity to \cbstart determine\cbend\ the criteria that a system will be judged on. The \gls{odr} assessment links directly to the sub-tasks identified by \acrshort{iso} 31000 for establishing the risk assessment context and introduces aspects to guide the assessor \cbstart in assessing\cbend\  data-specific risks.

Questions 2, 3 and 4 of the \gls{odr} align directly with\cbstart\ activity 6.3.3 from \acrshort{iso} 31000: establishing the external context of the risk assessment.
They guide the assessor in assessing\cbend\ the risk appetite of external \index{Stakeholder}\glspl{stakeholder}, the level of risk that is allocated to the organization, and the regulatory environment within the project will operate.

Question 5 \cbstart establishes the internal context of the risk assessment (Activity 6.3.3 from \acrshort{iso} 31000),
helping the assessor determine the maturity of the organization in terms of their attitude to risk and specifically to data-driven risks\cbend.

Question 6 explores \index{Data!Owner}data ownership through the use cases of the system. This is related to the legal frameworks explored in question 4, but also acts to lay the foundations of activity 6.3.4 \cbstart from \acrshort{iso} 31000\cbend,
defining risk criteria, which requires an assessor to identify ``the nature and types of causes and consequences that can occur and how they will be measured''. \cbstart Questions 1, 7 and 8 expand on this, considering data-driven specifics of\cbend\ failure consequences and the issues raised by data complexity, boundary complexity, and system complexity for the project.

Finally, the scoring system of the \gls{odr} provides a heuristic for defining the risk criteria
(Activity 6.3.4 \cbstart from \acrshort{iso} 31000\cbend)
which \cbstart determines\cbend\ how to combine these different aspects of risk into a single, high-level estimate of the data-related risks associated with a given project. This means that the \gls{odr} can, for example, provide some guidance on data safety assurance principle ``4 + 1''; that is, it provides some guidance on the amount of effort that should be directed towards the management of data safety issues.
 
\cbstart While\cbend\ the completion of an \gls{odr} fits within the context establishment activity, it also augments the ongoing communication and consultation activity both by providing a standardised format for capturing the relevant \gls{information} and securing endorsement.

\subsubsection{Data Safety Culture Questionnaire}
\cbstart The \gls{odr} assessment includes\cbend\ assessing the organization's maturity in managing data safety risks; \cbstart the questions\cbend\ are aimed at establishing the depth of awareness of data safety and the associated management processes within the organization. However, measuring the level of awareness of processes and concepts in an organization is not always easy. There may be sufficient high-level knowledge of this for the purposes of the \gls{odr}, but it still may be an area that warrants further investigation.

To support this, \cbstart\autoref{bkm:culture} includes a separate data safety culture questionnaire to explore the specific area of measuring the data safety culture for a particular activity, whether this be for the organization as a whole or for a particular project, service, or activity. Here the focus is on a personal view rather than a project or company view, so the questionnaire would be completed by all or a significant subset of staff. \index{Response}\Glspl{response} can be aggregated to give an overall data safety culture value. This approach can be periodically repeated to determine trends. For example, if overall scores are declining this may suggest that further training and briefings will be required.\cbend\

\subsubsection{System Definition}
The system under consideration should be understood and documented, including interfaces\index{Interface!System} and safety-related data aspects. The process of documenting the system of interest furthers the understanding of \index{Stakeholder}\glspl{stakeholder} and approvers so they can make sensible judgements about the system. It also formally declares assumptions that are being made\cbstart\ in the system assessment\cbend\ and clearly defines the limits of the assessment. In addition, different levels of risk may be associated with composites of safety-related data, which may be easier to manage than individual \index{Artefact, Data}\cbstart\glspl{data artefact}\cbend, or where independence cannot be demonstrated or maintained. Hence, the partitioning of \glspl{dataset} should also be considered during this phase.

\subsubsection{Supplier Data Maturity}
As \cbstart already noted, some usage scenarios involve data being supplied by subcontracted organizations. Some formal process will typically be used to select these suppliers. \autoref{bkm:maturity} includes a questionnaire to help ensure that the supplier has suitable processes in place to manage data safety-related issues.\cbend.

\subsubsection{Data Categories\index{Category!Data|textbf}}
\label{bkm:datacategories}
The full set of data categories which can have safety implications is large: to date more than twenty categories (and one meta-category) have been identified. 

\cbstart\autoref{tab:CategoriesShort} gives the current view of the categories of safety-related data that contribute to, are used by, produced by, or affected by safety-related systems. They are roughly organized into a number of categories\index{Category!Data}, which aim to cover all aspects of the system lifecycle\index{Lifecycle!System}. The list in \autoref{tab:CategoriesShort} is not exhaustive. A more detailed version of this table is given in \autoref{bkm:categories}.\cbend\

\begin{longtable}{|C{\dsiwgColumnWidth{0.1}}|L{\dsiwgColumnWidth{0.2}}|L{\dsiwgColumnWidth{0.7}}|}
  \caption{Categories\index{Category!Data} of safety-related data: concise definitions}
  \label{tab:CategoriesShort}
  \\\hline\TableHeadColourCX{No.} & \TableHeadColour{Category} & \TableHeadColour{Description}\\\hline
  \endfirsthead
  \caption[]{Categories of safety-related data: concise definitions (continued)}
  \\\hline\TableHeadColourCX{No.} & \TableHeadColour{Category} & \TableHeadColour{Description}\\\hline
  \endhead
  \multicolumn{3}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  \multicolumn{3}{|c|}{\dsiwgTextBF{Context}}\\\hline
  {1} & {Predictive}\index{Predictive Data} & {Data used to model or predict behaviours and performance}\\\hline
  {2} & {Scope, assumption and context}\index{Scope, Assumption and Context Data} & {Data used to frame the development, operations or provide context}\\\hline
  {3} & {Requirements}\index{Requirement Data} & {Data used to specify what the system has to do}\\\hline
  {4} & {Interface}\index{Interface Data} & {Data used to enable interfaces between this system and other systems:  for operations, initialisation or export from the system}\\\hline
  {5} & {Reference or lookup}\index{Reference or Lookup Data} & {Data used across multiple systems with generic usage}\\\hline
  \multicolumn{3}{|c|}{\dsiwgTextBF{Implementation}}\\\hline
  {6} & {Design and development}\index{Design and Development Data} & {Data produced during development  and implementation}\\\hline
  {7} & {Software}\index{Software Data} & {Data that is compiled (or interpreted) and executed to achieve the desired system behaviour}\\\hline
  {8} & {\Gls{verification}}\index{Verification Data} & {Data used to test and analyse the system,
    specifically to determine whether it has been built as intended}\\\hline
  \multicolumn{3}{|c|}{\dsiwgTextBF{Configuration}}\\\hline
	{9} & {\Gls{ml}}\index{Machine Learning Data} & {Data used to train the system}\\\hline
  {10} & {Infrastructure}\index{Infrastructure Data} & {Data used to configure, tailor or instantiate the system itself}\\\hline
  {11} & {Behavioural}\index{Behavioural Data} & {Data used to change the functionality of the system}\\\hline
  {12} & {Adaptation}\index{Adaptation Data} & {Data used to configure to a particular site}\\\hline
  \multicolumn{3}{|c|}{\dsiwgTextBF{Capability}}\\\hline
  {13} & {Staffing}\index{Staffing Data} & {Data related to staff training, competency, certification and permits}\\\hline
  \multicolumn{3}{|c|}{\dsiwgTextBF{The Built System}}\\\hline
  {14} & {Asset}\index{Asset Data} & {Data about the installed or deployed system and its parts, including maintenance data}\\\hline
  {15} & {Performance}\index{Performance Data} & {Data collected or produced about the system during trials, pre-operational phases and live operations}\\\hline
  {16} & {Release}\index{Release Data} & {Data used to ensure safe operations per release instance}\\\hline
  {17} & {Instructional}\index{Instructional Data} & {Data used to warn, train or instruct users about the system}\\\hline
  {18} & {Evolution}\index{Evolution!Data} & {Data about changes after deployment}\\\hline
  {19} & {End of Life}\index{End of Life Data} & {Data about how to stop, remove, replace or dispose of the system}\\\hline
  {20} & {Stored}\index{Stored Data} & {Data stored by the system during operations}\\\hline
  {21} & {Dynamic}\index{Dynamic Data} & {Data manipulated and processed by the system during operations}\\\hline
  {22} & {Twinning}\index{Twinning Data} & {Data used to create and maintain a digital counterpart of a physical object or process}\\\hline
%
  \multicolumn{3}{|c|}{\dsiwgTextBF{Compliance and Liability}}\\\hline
  {23} & {Standards and regulatory}\index{Standards and Regulatory Data} & {Data that governs the approaches,  processes and procedures used to develop safety systems}\\\hline
  {24} & {Justification} & {Data used to justify the safety position of the system}\\\hline
  {25} & {Investigation}\index{Investigation Data} & {Data used to support accident or incident investigations (i.e., potential evidence)}\\\hline
  \multicolumn{3}{|c|}{\dsiwgTextBF{Meta-Property}}\\\hline
  {+1} & {Trustworthiness}\index{Trustworthiness Data} & {(Meta) data which tells us how much the system can be trusted}\\\hline
\end{longtable}

\subsection{Identify Risks}
\subsubsection{Historical Accidents and Incidents}
Ideally, data safety risks would be identified and mitigated before they led to an accident or incident. However, this is not always the case. Historical occurrences can provide an indication of the data safety risks present in planned or existing systems. In particular, accidents and incidents can be analysed to identify potential contributory causes relating to data.

To support this type of analysis a number of previous accidents and incidents have been collected in \autoref{bkm:accidents}.
These include cases which relate to a number of \glspl{data property} (see
\hyperref[bkm:guidance:dataproperties]{section}~\ref{bkm:guidance:dataproperties}), %Clunky, but \autoref inserted "subsubsection"
for example the properties of \index{Completeness!Property}\gls{completeness}, \index{Integrity Property}\gls{integrity} and \gls{timeliness}\index{Timeliness Property}.
They also highlight the importance of the \gls{adaptation data}\index{Adaptation Data} category\index{Category!Data} and dangers associated with the inappropriate use of default data values.

Most of the current collection of accidents and incidents fall into three categories: aviation, maritime, and medical. However, the lessons that can be learned span a much wider range of application areas.

\subsubsection{Ways that Data Can Cause Problems}
\label{tab:issues}
There are some risk-inducing issues that are different or more prevalent for data than for other system elements. An incomplete collection of examples is provided below. This list may provide a quick way of identifying risks, which could be especially useful at an early stage of a project:

\begin{description}
\item[Fluidity:] Hardware and software can undergo significant amounts of product assurance and once assured may change relatively infrequently. Where change is required to hardware or software, it can be carefully managed and the impact on the safety case appraised. This is not always the case for data, which is often much more fluid. Indeed the ease with which data can be changed is one motivation for the move towards \glspl{data-driven system}. This fluidity means that it is not always possible to revisit safety cases when data changes. For example, the safety case for an autonomous vehicle cannot be updated every time that the vehicle acquires new knowledge during operation. Instead, the fact that data can change, along with any associated safety impacts, may need to be captured in the system safety case. Fluidity can also provide a temptation for unscrupulous operators to falsify data, for example, after an incident has occurred. Rigorous configuration control procedures can help protect against this type of behaviour.

\item[Reuse:] For the purposes of this discussion, ``reuse'' is interpreted as use of the same data in a different system or system context (e.g., lifecycle\index{Lifecycle!System} phase). Just because data was valid for use in a particular system, it does not immediately follow that it can be reused again in a similar system. Many considerations associated with data reuse are similar to those of software reuse, for example, similarity of requirements, similarity of role in the system, and similarity of required \index{Integrity Property}\gls{integrity} / \index{Assurance Level}assurance level. One consideration that is different is that of \gls{timeliness}\index{Timeliness Property}: data that was valid for use in a particular system at a particular time is not necessarily valid for reuse in the same system at a different time.

\item[Ageing:] As highlighted above, all safety-related data has a lifetime and this needs to be explicitly managed. This can involve, for example, purging, deleting and alerting. \cbstart Ageing can occur as a result of changes external to the system (for example, records of the positions of other aircraft, newly discovered drug interactions, or new software patches), or it can result from internal changes (e.g., valves gradually becoming less responsive, \gls{configuration data} becoming out of date, or data schemas evolving over time).\cbend\

\item[Transformation:] Data is often filtered, mapped or aggregated as it moves through systems, sometimes creating new \glspl{dataset} as a result. \Glspl{data property} are not necessarily preserved by these processes. Sometimes data is filtered too much or only some of the data is selected (either deliberately or inadvertently through accident or unintended bias), such as by the selection of only the test runs that succeeded. The main issues are loss of heritage / history / source \gls{information}. Data can also appear to become something else. Without careful management, the \index{Integrity Property}\gls{integrity} may become lowered to the lowest common denominator and this needs to be recognized. Additional checks (e.g., \gls{validation} checks,\cbstart\ credibility\cbend\ checks) or assurance measures may \cbstart be needed\cbend\ to ensure that required \index{Integrity Property}\gls{integrity} / assurance is maintained.

\item[Archiving and retrieval:] Safety-related data needs to be available when required. \cbstart Data \gls{accessibility}\index{Accessibility Property} needs to be considered\cbend over the complete system lifetime. It is also important to consider what \index{Property!Data}properties of the data need to be preserved and how this affects the choice of storage medium.

\item[Biasing:] This is a systemic \index{Accuracy Property}inaccuracy in data due to the characteristics of the process employed in the creation, collection, manipulation, presentation, and interpretation of data. It is usually an unintentional distortion in the \gls{dataset}. One example of this is the confirmation bias that may be applied to safety claims, and another example is that synthetic autonomous vehicle training \glspl{database} can have issues with artificial data if it is not realistic.
Although there is no perfect way of checking for this within the system, \index{Completeness!Checks}\gls{completeness}, statistical and validity checks on \glspl{dataset} may help.

\item[Falsification / misinformation:] This issue arises where data is created, modified, or deleted either accidentally or deliberately so as to mislead or misinform potential consumers of that data. Examples from policing and criminal justice might \cbstart include notes being taken with fabricated times or dates or a crime from the wrong individual in a \gls{database} being accidentally added or removed\cbend. Another example might be a supplier falsifying quality records for materials or goods. There have been many cases of misinformation related to the Covid-19\index{Covid-19} pandemic (for example on social media) where people have been deliberately misled, and sometimes this has led to harm (\cbstart for example, bleach being drunk as a cure\cbend). \cbstart Possible \glspl{mitigation}\index{Mitigation}\cbend\ include digitally signing transmitted data, strong access controls, independent fact-checking, and audit records.

item[Defaulting:] Many systems use default or initial values for \glspl{item data}; sometimes in \glspl{dataset} and sometimes embedded in software. Often these default values are designed to be neutral (e.g., ``0'') or unrealistic (e.g., ``VOID''). There are essentially two cases:
\begin{enumerate}
	\item initialisation data which may persist and be mistakenly taken as a real value when in fact it should have been changed; and
	\item data that is used when no meaningful value has been assigned (e.g., during data migration or data exchange between systems).
\end{enumerate}	
These issues can often be managed through good design of data structures, for example by the inclusion of a validity flag.

\item[Sentinels:] A sentinel value is a data value that is used to indicate a special action needs to be taken, typically indicating the end of a record or a \gls{dataset}. The sentinel value should be one that is not allowable in the \gls{dataset} itself, but often is not properly considered and may use common sequences (e.g., five zeroes). Sentinels can cause problems in two ways:
\begin{enumerate}
	\item where they are not recognized and so, for example, processing \cbstart includes or continues\cbend\ past the sentinel; and
	\item where the data itself somehow contains the sentinel value and so processing is erroneously interrupted.
\end{enumerate}
Sentinels can be a particular risk in long-lived systems and \glspl{dataset}. As with \cbstart defaulting\cbend, the management or elimination of this issue may often be achieved through improved data structures.

\item[Aliasing:] This is an effect that causes different data to become indistinguishable when accessed; that is, there is only one record when there should be several -- for example, two patients with similar names inadvertently sharing a single set of medical records. This could be due to the way the data is filtered, sampled, indexed, stored, or retrieved. The data issues are typically related to loss of resolution leading to similar data points appearing to be identical. \cbstart Methods to maintain resolution, including use of unique indexes, may be beneficial.\cbend\

One specific case of aliasing \cbstart\ concerns \cbend homophones -- words which sound the same but are different such as ``flower'' / ``flour'' and ``bare'' / ``bear'' \cite{citation:homonym}.
If these words are read out over a phone there may be confusion as to which is intended.
Location services based on a number of words such as W3W don't avoid all homophones,
and so there may be issues when the words are given verbally in an emergency. The issue is discussed further in \autoref{bkm:incacc:w3w}.

\item[Disassociation:] This effect is, in some senses, the opposite of aliasing: there are several records when there should only be one. This could occur, for example, if two records are created for the same individual using slightly different names. It could also arise if different systems use different indexing methods and the association between the indexes becomes corrupted. Again, methods to maintain data resolution can be beneficial.

\item[Masking:] This issue can arise if a notable proportion of a \gls{dataset} is of a poor \cbstart\gls{quality}\cbend, for example, if sensors producing the data are faulty or measurements are taken from the wrong source. This poor quality data can mask errors in the way that the system handles the good quality data. One way of protecting against this issue is the generation and use of test sets of appropriate size and quality, although for some applications this may be a non-trivial task.

\item[Incompleteness:]\index{Completeness!Property} Not all the data that is needed is always available; there may be known, and sometimes, unknown gaps or missing data points. The missing data points ("dark data"\index{Dark Data} -- see \autoref{bkm:darkdata}) can be critical and in some cases, more important than the data that is available. Incomplete data can arise, for example, from limitations on how much data can be physically captured (eg.~sampling frequencies, storage / time constraints) or from the unintentional or deliberate darkening of data (eg.~for privacy, security, political or commercial reasons).

item[Volume:] Data can be so large and unstructured that it is not manageable in practicable timeframes.
For example, video records of rail track could take days to inspect manually.

\item[Interpretation:] Data can be misinterpreted -- too much or too little deduced from available data, or data extrapolated incorrectly to derive unsound results.
An example is \gls{ml} data\index{Machine Learning Data}, especially real or recorded data that may not contain critical edge / corner cases.

\item[Distribution:] Data can be decentralised, decomposed or distributed across many sources (e.g. channels, \glspl{database}, websites) and needs to be consistently integrated to make a coherent picture. In the health sector\cbstart\ many IT systems often \cbend have to work together feeding in different parts of a patient medical record to make a complete health picture. If parts of this distributed data are missing (for instance diagnostic test results) then it is difficult if not impossible to obtain the complete picture, and mistakes may be made.
There are several parts to this problem:
\begin{description}
	\item[Integration] -- multiple elements of data have to be brought together in a coherent way, addressing aspects such as which data should supercede or replace other data;
	\item[Communication] -- having correct and current \gls{information} about what data is available and its location so it can be requested; and
	\item[Contingency:] -- what to to if part of the distributed data is unavailable or late.
\end{description}
\end{description}


Further examples of how data may cause issues in many scenarios is given in \cbstart the book \dsiwgTextIT{Data-Centric Safety: Challenges, Approaches, and Incident Investigation} \cite{citation:datacentric}\cbend.

\subsubsection{\ecapitalisewords{\glsentryplural{data property}}}\label{bkm:guidance:dataproperties}
\Glspl{data property} are used to establish what aspects of the data (e.g., \gls{timeliness}\index{Timeliness Property}, \gls{accuracy}\index{Accuracy Property}) need to be guaranteed in order that the system operates in a safe manner.

James Inge's work \cite{citation:inge2008improving} produced a useful taxonomy of data categories, and went on to look at faults in data. He concluded that a rigid taxonomy of data categories was unhelpful due to various properties or characteristics of the data which vary independently. In short, it is the combination of data category\index{Category!Data} with the required \index{Property!Data}\glspl{data property} that facilitates safety analysis.

Data categories were discussed in the preceding phase. \cbstart\autoref{tab:PropertiesOfData} documents a non-exhaustive collection of \index{Property!Data}\glspl{data property}. Typically, it is the loss of one of these \glspl{data property} that presents a \gls{hazard}. This notion of ``loss'' is dependent on the intended use; for example, what is ``timely'' for one use may not be for another.\cbend\

The ``\Gls{goldilocks}'' property \cbstart addresses\cbend\ appropriate sizing and quantity of data. A number of issues have been found to arise when there is too much or too little data. While it is particularly relevant to communications links, it may have relevance to other areas such as \glspl{database} and when people are involved in reviewing or checking data. The property is named ``\gls{goldilocks}'' as it refers to the need to have not too much, not too little, but just the right amount of data%
%
\footnote{A system where the property was lost involved a high speed \cbstart data\cbend\ bus that connected several safety-critical systems. A transceiver of that bus failed and transmitted random noise. The receivers employed parity checks and cyclic redundancy check, but the system had been designed to eliminate occasional \cbstart\glspl{error}\cbend. When random noise filled the bus, several apparently valid messages were created every second, resulting in potentially lethal behaviour.

In a \gls{hazop}\index{HAZOP} carried out during 2020, based upon the \gls{hazop}\index{HAZOP} guidewords \cbstart in this guidance\cbend, the facilitator realised that certain failure modes had not been identified by the \gls{hazop} team. In addition to the issue of system overload already discussed, those omissions also concerned system behaviour following data rejection. In these cases, bad data was detected and rejected, but the consequences of data rejection over an extended period had not been considered.}.

The \gls{goldilocks}\index{Goldilocks Property} property is related to the \cbstart data volume problem \cbend\ discussed in \hyperref[tab:issues]{section}~\ref{tab:issues}, however, given the importance of data sizing and the experience of real-world incidents this is now a separate property.

%
\paragraph{The \glsfmttext{analysability}\index{Analysability Property|textbf} property}\label{bkm:guidance:analysability}
The \gls{analysability} property \cbstart recognizes\cbend\ that data is now \cbstart\ highly complex and extensive, often large scale, and distributed. And yet, for safety purposes we need to make sure it is of suitable quality and able to support system goals.\cbend\
We therefore need to ensure that it is possible to analyse it for key characteristics and \cbstart establish meaningful results using tools or other means.\cbend\ This property is related to explainabilty and may be performed by the same set of tools or techniques.

\paragraph{The \glsfmttext{explainability}\index{Explainability Property|textbf} property}\label{bkm:guidance:explainability}
\Gls{explainability} \cbstart describes the ability to establish what the purpose and effect data (and especially changes to data) has on a system
and explain this to relevant \glspl{stakeholder} in terms that they can understand. It is particularly important for learning and AI-based systems.\cbend\
This could be, for example, \gls{ml} training data or system \gls{configuration data}.
This property is related to \gls{analysability}\index{Analysability Property} and may be performed by the same set of tools or techniques.
%

\begin{longtable}{|L{\dsiwgColumnWidth{0.24}}|C{\dsiwgColumnWidth{0.15}}|L{\dsiwgColumnWidth{0.61}}|}
  \caption{\index{Property!Data}Properties of data}
  \label{tab:PropertiesOfData}
  \\\hline\TableHeadColour{Property} & \TableHeadColour{Abbreviation} & \TableHeadColour{Description}\\\hline
  \endfirsthead
    \caption[]{Properties of data (continued)}
  \\\hline\TableHeadColour{Property} & \TableHeadColour{Abbreviation} & \TableHeadColour{Description}\\\hline
  \endhead
  \multicolumn{3}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  {\Gls{integrity}}\index{Integrity Property} & I & {The data is correct, true and unaltered}\\\hline
  {\Gls{completeness}}\index{Completeness!Property} & C & {The data has nothing missing or lost}\\\hline
  {\Gls{consistency}}\index{Consistency!Property} & N & {The data adheres to a common world view (e.g., units)}\\\hline
  {\Gls{continuity}}\index{Continuity Property} & Y & {The data is continuous and regular without gaps or breaks}\\\hline
  {\Gls{format}}\index{Format Property} & O & {The data is represented in a way which is readable by those that need to use it}\\\hline
  {\Gls{accuracy}}\index{Accuracy Property} & A & {The data has sufficient detail for its intended use}\\\hline
  {\Gls{resolution}}\index{Resolution Property} & R & {The smallest difference between two adjacent values that can be represented in a data storage, display or transfer system}\\\hline
  {\Gls{traceability}} & T & {The data can be linked back to its source or derivation}\\\hline
  {\Gls{timeliness}}\index{timeliness Property} & M & {The data is as up to date as required}\\\hline
  {\Gls{verifiability}}\index{Verifiability Property} & V & {The data can be checked and its properties demonstrated to be correct}\\\hline
  {\Gls{availability}}\index{Availability Property} & L & {The data is accessible and usable when an authorized entity demands access}\\\hline
  {\Gls{fidelity}}\index{Fidelity / Representation Property} & F & {How well the data maps to the real-world entity it is trying to model}\\\hline
  {\Gls{priority}}\index{Priority Property} & P & {The data is presented / transmitted / made available in the order required}\\\hline
  {\Gls{sequencing}\index{Sequencing, Data}} & Q & {The data is preserved in the order required}\\\hline
  {\Gls{intended_destination}}\index{Intended Destination / Usage Property} & U & {The data is only sent to those that should have
  access to
  it}\\\hline
  {\Gls{accessibility}}\index{Accessibility Property} & B & {The data is visible only to those that should see it}\\\hline
  {\Gls{suppression}}\index{Suppression Property} & S & {The data is intended never to be used again}\\\hline
  {\Gls{history}}\index{History Property} & H & {The data has an audit trail of changes}\\\hline
  {\Gls{lifetime}}\index{Lifetime Property} & E & {When does the safety-related data expire}\\\hline
  {\Gls{disposability}}\index{Disposability / Deletability Property} & D & {The data can be permanently removed when required}\\\hline
  {\Gls{goldilocks}\index{Goldilocks Property}} & G & {The data is just the right size -- not too much and not too little}\\\hline
  {\Gls{analysability}\index{Analysability Property}} & Z & {The data (including any \gls{metadata}) is of a suitable size, type and\cbstart\ format\cbend\ to enable it be usefully analysed}\\\hline
  {\Gls{explainability}\index{Explainability Property}} & X & {The data can be meaningfully explained,by a suitable mechanism, to those who need to understand it}\\\hline
\end{longtable}

\autoref{tab:issuesCrossReference} illustrates where the data issues discussed in
\hyperref[tab:issues]{Section}~\ref{tab:issues} %Clunky, but \autoref inserted "subsubsection"
can result in
loss of one or more \index{Property!Data}data properties (x = potential loss of property).

\begin{longtable}{|L{\dsiwgColumnWidth{0.16}}|%
    C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|%
    C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|%
    C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|%
    C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|%
    C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|%
    C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|}
  \caption{Properties that can be lost through issues}
  \label{tab:issuesCrossReference}
  \\\hline
  & \rotatebox{90}{\index{Integrity Property}\Gls{integrity}}
  & \rotatebox{90}{\index{Completeness!Property}\Gls{completeness}}
  & \rotatebox{90}{\index{Consistency!Property}\Gls{consistency}}
  & \rotatebox{90}{\index{Continuity Property}\Gls{continuity}}
  & \rotatebox{90}{\Gls{format}\index{Format Property}}
  & \rotatebox{90}{\index{Accuracy Property}\Gls{accuracy}}
  & \rotatebox{90}{\index{Resolution Property}\Gls{resolution}}
  & \rotatebox{90}{\Gls{traceability}}
  & \rotatebox{90}{\Gls{timeliness}\index{Timeliness Property}}
  & \rotatebox{90}{\Gls{verifiability}}\index{Verifiability Property}
  & \rotatebox{90}{\index{Availability Property}\Gls{availability}}
  & \rotatebox{90}{\index{Fidelity / Representation Property}\Gls{fidelity}}
  & \rotatebox{90}{\Gls{priority}}\index{Priority Property} & \rotatebox{90}{\Gls{sequencing}\index{Sequencing, Data}}
  & \rotatebox{90}{\Gls{intended_destination}\index{Intended Destination / Usage Property}\ }
  & \rotatebox{90}{\Gls{accessibility}\index{Accessibility Property}}
  & \rotatebox{90}{\Gls{suppression}\index{Suppression Property}}
  & \rotatebox{90}{\Gls{history}\index{History Property}}
  & \rotatebox{90}{\Gls{lifetime}\index{Lifetime Property}}
  & \rotatebox{90}{\Gls{disposability}\index{Disposability / Deletability Property}}
  & \rotatebox{90}{\Gls{goldilocks}\index{Goldilocks Property}}
  & \rotatebox{90}{\Gls{analysability}\index{Analysability Property}}
  & \rotatebox{90}{\Gls{explainability}\index{Explainability Property}}
  %
  \\\hline\TableHeadColour{Issue} &%
  \TableHeadColour{I} & \TableHeadColour{C} & \TableHeadColour{N} & \TableHeadColour{Y} &%
  \TableHeadColour{O} & \TableHeadColour{A} & \TableHeadColour{R} & \TableHeadColour{T} &%
  \TableHeadColour{M} & \TableHeadColour{V} & \TableHeadColour{L} & \TableHeadColour{F} &%
  \TableHeadColour{P} & \TableHeadColour{Q} & \TableHeadColour{U} & \TableHeadColour{B} &%
  \TableHeadColour{S} & \TableHeadColour{H} & \TableHeadColour{E} & \TableHeadColour{D} &%
  \TableHeadColour{G} & \TableHeadColour{Z} & \TableHeadColour{X}\\\hline
  \endfirsthead
    \caption[]{Properties that can be lost through issues (continued)}
    \\\hline
    & \rotatebox{90}{\index{Integrity Property}Integrity}
    & \rotatebox{90}{\index{Completeness!Property}\Gls{completeness}}
    & \rotatebox{90}{\index{Consistency!Property}\Gls{consistency}}
    & \rotatebox{90}{\index{Continuity Property}Continuity}
    & \rotatebox{90}{\Gls{format}\index{Format Property}}
    & \rotatebox{90}{\index{Accuracy Property}Accuracy}
    & \rotatebox{90}{Resolution\index{Resolution Property}}
    & \rotatebox{90}{Traceability}
    & \rotatebox{90}{Timeliness\index{Timeliness Property}}
    & \rotatebox{90}{Verifiability}\index{Verifiability Property}
    & \rotatebox{90}{\index{Availability Property}Availability}
    & \rotatebox{90}{\Gls{fidelity}\index{Fidelity / Representation Property}}
    & \rotatebox{90}{\gls{priority}} & \rotatebox{90}{Sequencing\index{Sequencing, Data}}
    & \rotatebox{90}{\Gls{intended_destination}\index{Intended Destination / Usage Property}\ }
    & \rotatebox{90}{\Gls{accessibility}/index{Accessibility Property}}
    & \rotatebox{90}{\Gls{suppression}\index{Suppression Property}}
    & \rotatebox{90}{\Gls{history}\index{History Property}}
    & \rotatebox{90}{\Gls{lifetime}\index{Lifetime Property}}
    & \rotatebox{90}{\Gls{disposability}\index{Disposability / Deletability Property}}
    & \rotatebox{90}{\Gls{goldilocks}\index{Goldilocks Property}}
    & \rotatebox{90}{\Gls{analysability}\index{Analysability Property}}
    & \rotatebox{90}{\Gls{explainability}\index{Explainability Property}}
    %
    \\\hline\TableHeadColour{Issue} &%
    \TableHeadColour{I} & \TableHeadColour{C} & \TableHeadColour{N} & \TableHeadColour{Y} &%
    \TableHeadColour{O} & \TableHeadColour{A} & \TableHeadColour{R} & \TableHeadColour{T} &%
    \TableHeadColour{M} & \TableHeadColour{V} & \TableHeadColour{L} & \TableHeadColour{F} &%
    \TableHeadColour{P} & \TableHeadColour{Q} & \TableHeadColour{U} & \TableHeadColour{B} &%
    \TableHeadColour{S} & \TableHeadColour{H} & \TableHeadColour{E} & \TableHeadColour{D} &%
    \TableHeadColour{G} & \TableHeadColour{Z} & \TableHeadColour{X}\\\hline
  \endhead
  \multicolumn{22}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  Fluidity       &   &   &   &   &   &   &   & x &   & x &   & x &   &   &   &   &   & x &   &   & x & x & x \\\hline
  Reuse          &   & x &   &   &   & x &   & x & x & x &   & x &   &   & x &   & x & x & x & x & x &   & x \\\hline
  Ageing         &   & x &   &   &   & x &   &   & x &   &   & x &   &   & x & x & x & x & x & x & &   & x \\\hline
  Transformation & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x \\\hline
  \index{Data!Owner}Ownership      &   &   &   &   &   &   &   & x &   & x & x &   &   &   & x & x &   & x &   &   &   &   & x \\\hline
  Archiving / Retrieval &   &   &   &   &   &   &   &   &   &   &   &   &   &   & x & x & x & x & x & x &   & x & \\\hline
  Biasing        & x & x & x & x &   & x &   &   & x & x &   & x & x & x &   &   &   &   &   &   &   & x & x \\\hline
  Falsification / misinformation & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x \\\hline
  Defaulting     & x & x & x & x &   & x &   &   &   &   &   & x &   &   &   &   &   &   &   &   &   & x & \\\hline
  Sentinels      & x & x &   & x &   & x &   &   &   &   &   &   &   & x &   &   &   &   &   &   &   & x & \\\hline
  Aliasing       & x & x &   & x &   & x & x & x &   & x & x & x &   &   &   &   &   &   &   &   &   & x & x \\\hline
  Disassociation & x &   &   & x &   & x &   & x & x & x & x & x & x & x & x & x & x & x & x & x &   & x & x \\\hline
  Masking        & x & x & x & x &   & x &   &   &   & x &   & x &   &   &   &   &   &   &   &   &   & x & x \\\hline
  \index{Completeness!Property}Incompleteness & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x & x \\\hline
  Volume         &   &   &   &   &   &   &   &   &   & x &   &   &   &   &   &   &   &   &   &   & x & x & x \\\hline
  Interpretation & x & x & x &   & x & x & x &   & x & x &   & x &   &   &   &   &   &   &   &   &   & x & x \\\hline
  Distribution   & x & x & x & x &   &   &   & x &   &   & x &   & x & x & x & x &   & x &   & x &   & x & x \\\hline
\end{longtable}
\clearpage
\subsubsection{\glsfmtshort{hazop} Guidewords}\index{HAZOP}
\label{bkm:HazopGuidewords}
A \gls{hazop} \cite{citation:iec61882:2016}
provides a structured approach for identifying hazards. It involves a multidisciplinary team collaborating to identify potential hazards and operability problems. Structure and \index{Completeness!Hazard Identification}\gls{completeness} are supported through the use of guideword prompts, for example, considering the implications if software components perform functions early, late or not at all. These prompts are intended to stimulate imaginative thinking, to focus the study and to elicit ideas and discussion.

\autoref{tab:HazopShort}\index{HAZOP} lists a set of guidewords for a data-focused \gls{hazop}, based upon the \index{Property!Data}properties defined in \autoref{tab:PropertiesOfData}. The intent here is to assess the impact of each guideword on the property under consideration. For example, the first row considers \dsiwgTextIT{loss} of \index{Integrity Property}\gls{integrity}, \dsiwgTextIT{partial loss} of \index{Integrity Property}\gls{integrity}, and so on.
The list is non-exhaustive. Other guidewords may be useful for particular systems, or may be used to ensure the data safety assessment is fully integrated within the system safety assessment\index{Safety Assessment!System}\index{System Safety Assessment|see{Safety Assessment, System}}. \cbstart A\cbend\ more detailed version of this table, including specific \gls{hazop}\index{HAZOP} data considerations, is available at \autoref{bkm:guidewords}.

\begin{longtable}{|L{\dsiwgColumnWidth{0.25}}|L{\dsiwgColumnWidth{0.75}}|}
  \caption{\glsfmtshort{hazop} guidewords: concise guide}\index{HAZOP}
  \label{tab:HazopShort}
  \\\hline\TableHeadColour{Property} & \TableHeadColour{\glsfmtshort{hazop} Data Guidewords}\\\hline
  \endfirsthead
  \caption[]{\glsfmtshort{hazop} guidewords: concise guide (continued)}
  \\\hline\TableHeadColour{Property} & \TableHeadColour{\glsfmtshort{hazop} Data Guidewords}\\\hline
  \endhead
  \multicolumn{2}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  {\Gls{integrity}}\index{Integrity Property} & {Loss, partial loss, incorrect, multiple}\\\hline
  {\Gls{completeness}}\index{Completeness!Property} & {Loss, partial loss, incorrect, multiple, insufficient}\\\hline
  {\Gls{consistency}}\index{Consistency!Property} & {Loss, partial loss, incorrect, multiple, too early, too late, loss of sequence}\\\hline
  {\Gls{continuity}}\index{Continuity Property} & {Loss, partial loss, incorrect, late, loss of sequence}\\\hline
  {\Gls{format}}\index{Format Property} & {Loss, partial loss, incorrect, multiple}\\\hline
  {\Gls{accuracy}}\index{Accuracy Property} & {Loss, partial loss, incorrect, multiple, insufficient}\\\hline
  {\Gls{resolution}\index{Resolution Property}} & {Loss, partial loss, incorrect, multiple, insufficient}\\\hline
  {\Gls{traceability}}\index{Traceability Property} & {Loss, partial loss, incorrect, multiple, too early, too late, loss of sequence}\\\hline
  {\Gls{timeliness}\index{Timeliness Property}} & {Loss, partial loss}\\\hline
  {\Gls{verifiability}}\index{Verifiability Property} & {Loss, partial loss, incorrect, multiple, too early, too late, loss of sequence}\\\hline
  {\Gls{availability}}\index{Availability Property} & {Loss, partial loss, multiple, too early, too late}\\\hline
  {\Gls{fidelity}}\index{Fidelity / Representation Property} & {Loss, partial loss, incorrect, multiple, too early, too late}\\\hline
  {\Gls{priority}}\index{Priority Property} & {Loss, partial loss, incorrect, multiple, too early, too late}\\\hline
  {\Gls{sequencing}\index{Sequencing, Data}} & {Loss, partial loss, incorrect, multiple}\\\hline
  {\Gls{intended_destination}\index{Intended Destination / Usage Property}} & {Loss, partial loss, incorrect, multiple, too early, too late, loss of sequence}\\\hline
  {\Gls{accessibility}}\index{Accessibility Property} & {Loss, partial loss, incorrect, multiple, too early, too late}\\\hline
  {\Gls{suppression}}\index{Suppression Property} & {Loss, partial loss, incorrect, too early, too late, too much, too little}\\\hline
  {\Gls{history}}\index{History Property} & {Loss, partial loss, incorrect, multiple}\\\hline
  {\Gls{lifetime}}\index{Lifetime Property} & {Loss, too early, too late, incorrect, multiple, loss of sequence}\\\hline
  {\Gls{disposability}}\index{Disposability / Deletability Property} & {Loss, partial loss, incorrect, too early, too late}\\\hline
  {\Gls{goldilocks}\index{Goldilocks Property}} & {Loss, partial loss, incorrect, too early, too late, too much,
    too little (insufficient), spurious}\\\hline
  {\Gls{analysability}\index{Analysability Property}} & {Loss, partial loss, incorrect, too much, too little, loss of sequence, loss of tooling}\\\hline
  {\Gls{explainability}\index{Explainability Property}} & {Loss, partial loss, incorrect, too early, too late, too much, too little, loss of sequence, loss of skills, loss of tooling}\\\hline
\end{longtable}

\clearpage
\subsection{Analyse Risks}
\subsubsection{Establishing \glsfmtplural{dsal}}\index{Assurance Level!Data}
\label{bkm:Establishing-DSALS}
\hyperref[bkm:DSAL-table-section]{Section}~\ref{bkm:DSAL-table-section} %Clunky, but \autoref inserted "paragraph"
presented a method for \cbstart assigning\cbend \gls{dsal}s, by combining severity and likelihood through a risk matrix, such as \autoref{tab:DSAL-risk-matrix}. This section describes approaches that may be used to determine the severity and likelihood appropriate to the loss of any given \index{Property!Data}property. In principle, \autoref {tab:Likelihood} and \autoref{tab:Severity} are used together with \autoref{tab:DSAL-risk-matrix} to determine a \gls{dsal}. However, \cbstart\ the methods to determine severity and likelihood, and to combine them to determine a \gls{dsal}, should not be followed rigidly, but should be defined based upon the overall \index{Safety Requirement!System}safety requirements of the system being assessed. Examples of situations that may require such alternate approaches are described in
\hyperref[bkm:activities:analyse:partofsystemsafetyactivities]{section}~\ref{bkm:activities:analyse:partofsystemsafetyactivities}, %Clunky, again avoidging "paragraph"
while potential approaches to customisation are described in \autoref{bkm:DsalCustomisation}.
It is essential that any customised approach is recorded in the \gls{dsmp}\cbend.

The likelihood of a data safety related risk is qualitatively determined by
consideration of the significance of a \gls{error}, along with the defences currently in place against such errors. These factors may be addressed by
considering the following characteristics:

\begin{description}
  \item[Proximity:] how directly a data failure will lead to an accident;
  \item[Dependency:] how dependent the application is on the \gls{dataset};
  \item[Preventability:] the ability of the systems architect / developers to guard against \cbstart\glspl{error}\cbend;
  \item[Detectability:] the likelihood of being able to detect a data failure prior to an accident; and
  \item[Correctability:] the ability of the system to work around or correct \cbstart\glspl{error}\cbend.
\end{description}

For example, errors that are easy to guard against are associated with low likelihoods. Conversely, errors that are difficult to detect are associated with high likelihoods. \autoref {tab:Likelihood} illustrates how aspects of these characteristics map to three, qualitative likelihoods.  \cbstart\ The table assumes the actions implied are taken. For example, a low likelihood for the ``prevention'' characteristic is only valid if the easy guard / barrier is actually implemented. Similarly, it is assumed that if an error is found, under the ``detection'' characteristic, an appropriate \index{Response}\gls{response} is implemented.\cbend\

\begin{longtable}{|C{\dsiwgColumnWidth{0.19}}|C{\dsiwgColumnWidth{0.27}}|C{\dsiwgColumnWidth{0.27}}|C{\dsiwgColumnWidth{0.27}}|}
  \caption{Calculation of Likelihood}
  \label{tab:Likelihood}
  \\\hline
  \TableHeadColour{} & \multicolumn{3}{c|}{\TableHeadColourCX{Likelihood}}\\\cline{2-4}
  \multirow{-2}*{\TableHeadColourCX{}} & \TableDimColourCX{ High} & \TableDimColourCX{Medium} & \TableDimColourCX{Low}\\\hline
  \endfirsthead
  \caption[]{Calculation of Likelihood (continued)}
  \\\hline\TableHeadColour{} & \multicolumn{3}{c|}{\TableHeadColourCX{Likelihood}}\\\cline{2-4}
  \multirow{-2}*{\TableHeadColourCX{}} & \TableDimColourCX{High} & \TableDimColourCX{Medium} & \TableDimColourCX{Low}\\\hline
  \endhead
  \multicolumn{4}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  Proximity & %
    A known use of the data is highly likely to lead to an accident. & %
    A possible use of the data could lead to an accident. & %
    All currently foreseen uses of the data could lead to harm only via lengthy and indirect routes.\\
    \hline
  Dependency & %
    Data is completely relied upon. & %
    Data is indirectly relied upon. & %
    Little reliance on data.\\
    \hline
  Prevention & %
    Difficult or impossible to \cbstart guard\cbend\ against errors. & %
    Possible to \cbstart guard\cbend\ against errors. & %
    Easy to \cbstart guard\cbend\ against error.\\
    \hline
  Detection & %
    Low or no chance of anything else detecting an error. & %
    Some other people / systems are involved in checking the data. & %
    Many other people / systems are involved in checking the data.\\
    \hline
  Correction & %
    Difficult or impossible to correct or workaround errors. & %
    Possible to correct or workaround errors. & %
    Easy to correct or workaround errors.\\
    \hline
\end{longtable}

\cbstart Consideration of different characteristics is likely to result in different likelihoods. The overall \gls{dsal}\index{Assurance Level!Data} is that 
associated with the lowest likelihood of any characteristic. Taking the lowest likelihood, not the highest, might  seem non-intuitive. However, in doing so, it is important to only apply those rows of the table which are valid for the issue under consideration. For example, if it would be easy to implement a guard against a given error, but that guard is not actually in place, it would not be valid to claim that the likelihood is low based on the prevention row. In theory it should always be possible to determine likelihood based upon proximity and dependency. However, the benefits of prevention, detection and correction will not always be present.\cbend\

Risk severity is estimated against a five-point scale, as indicated in \autoref{tab:Severity}.

%\clearpage
\begin{longtable}{|C{\dsiwgColumnWidth{0.2}}|L{\dsiwgColumnWidth{0.6}}|}
  \caption{Definition of Severity}
  \label{tab:Severity}
  \\\hline
  \TableHeadColourCX{Severity} & \TableHeadColour{Description}\\\hline
  \endfirsthead
    \caption[]{Definition of Severity (continued)}
  \\\hline
  \TableHeadColourCX{Severity} & \TableHeadColour{Description}\\\hline
  \endhead
    \multicolumn{2}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  Minor & %
    Minor injury or temporary discomfort for one or two people. Minor environmental impact.\\
    \hline
  Moderate & %
    \cbstart Minor\cbend\ injuries affecting several people or one serious injury. Some environmental impact.\\
    \hline
  Significant & %
    \cbstart Minor\cbend\ injuries affecting many people or a few serious injuries. Significant environmental impact.\\
    \hline
  Major & %
    \cbstart Serious\cbend\ injuries affecting a number of people, or a single death. Major environmental impact.\\
    \hline
  Catastrophic & %
    \cbstart Several deaths. Possibly affects the general public or has\cbend\ wide and catastrophic environmental impact.\\
    \hline
\end{longtable}

As noted earlier, \glspl{dsal}\index{Assurance Level!Data} have some commonality with things like \cbstart\glspl{idal} and \glspl{fdal})\cbend. However, this commonality does not extend across all aspects. For example, there is an accepted calculus of \glspl{fdal} in which two independent \index{Integrity Property}lower-\gls{integrity} functions can be used to replace a single \index{Integrity Property}higher-\gls{integrity} function. There are two reasons why this type of calculus is not appropriate for \glspl{dsal}:

\begin{enumerate}
  \item The definition of a \gls{dsal}\index{Assurance Level!Data} already caters for interactions. For example, using two independent \index{Artefact, Data}\glspl{data artefact} to provide similar \gls{information} to a system function reduces the ``dependency'' of each artefact.
  \item These types of consideration are most closely related to system architecture, from which \index{Artefact, Data}\glspl{data artefact}, associated \index{Property!Data}\glspl{data property} and risks are derived. Hence, rather than applying any calculus at the \gls{dsal}\index{Assurance Level!Data} tier it is more appropriate to apply this to, for example, \glspl{fdal}, with \glspl{dsal} changing as a consequence of the revised system definition.
\end{enumerate}

\subsubsection{Analysing \glsfmtplural{dsal}}\index{Assurance Level!Data}
When considering the possibility of data affecting software or software affecting data, the degree of contribution and existing \gls{mitigation}\index{Mitigation} position are important. The \glspl{mitigation} should be proportionate and full credit for existing \glspl{mitigation} may reduce or \cbstart remove\cbend\ the need for additional work. A particular case is the use of strong checksums to ``wrap'' the data. If these are preserved through processing and can be checked later on, then undetected  corruption \cbstart can\cbend\ be largely discounted.

\cbstart The with data affecting software is that the data used by the system might\cbend\ affect the software execution in a way that could credibly lead to \glspl{hazard}, but only where this data-induced effect is not easily detected or mitigated by other means. If this is the situation then appropriate measures need to be put in place \dsiwgTextIT{within the data} to mitigate this risk. Alternatively (or additionally), if the software within the system can be modified, \glspl{mitigation}\index{Mitigation} could be placed \dsiwgTextIT{within the software} to achieve or enhance the \gls{mitigation} needed:

\begin{description}
  \item[\Gls{mitigation} within the data:]\index{Mitigation} In many cases \cbstart\ this\cbend\ is the best or only option is to improve the quality of the data to avoid the issue. This can be done by introducing a \gls{dsal}\index{Assurance Level!Data} for the data, related to the severity of the \gls{hazard} which may be induced, and thereby addressing the issue at cause. In this case, the \gls{dsal} is bearing a large amount of responsibility. This may mean that a greater number of the ``recommended'' risk \index{Treatment!Risk}\gls{treatment} methods and approaches (identified in the following phase) need to be implemented.
  \item[\Gls{mitigation} within the software:] If the data cannot be assured to a \gls{dsal}\index{Assurance Level!Data} (e.g., if it is supplied by a third party or legacy system), sometimes changes can be made to the software in the system to improve the situation. These \glspl{mitigation} could be functional (e.g., introduction of better range checking, rejection of illegal combinations of data values). This requires not only specific software changes but also associated \gls{verification} of these new features, and any software changes will have to be implemented to an appropriate \index{Assurance Level!Software}\gls{software assurance level}. However there may be no particular functional \cbstart \glspl{mitigation}\index{Mitigation} that can be targeted at the particular issue (e.g., testing for illegal combinations of values might be\cbend\ too complex). \cbstart In this case, development (or re-development) to a suitable \index{Assurance Level!Software}\gls{software assurance level} of the complete set of software within the system should be considered\cbend\
\end{description}

\cbstart The issue with software affecting data\cbend\ is that the software may affect (e.g., corrupt, delete) the data in a way that key \index{Property!Safety}safety properties may be lost and\cbstart that such\cbend\ loss may not be easily detected. In general the key \index{Property!Data}\glspl{data property} should be considered to see if any important ones for this data may be jeopardised. If so, a \index{Assurance Level!Software}\gls{software assurance level} from an appropriate standard or guideline should be introduced that mitigates this risk of undetected property loss. This \index{Assurance Level!Software}\gls{software assurance level} should be determined by the hazards that could be caused, and may be localised to the software that can cause the problem.

However there are specific functional and architectural approaches that may reduce or avoid the need for a \index{Assurance Level!Software}\gls{software assurance level}, including use of strong checksums and digital signatures, as well as techniques such as storing multiple copies, independent channels and so on. \cbstart The\cbend\ software performing the check of the \index{Property!Data}\gls{data property} will itself need to be developed to the introduced \index{Assurance Level!Software}\gls{software assurance level}. The key is to establish what the software in the system is doing to the data: if the operations are simple and non-changing, then the risk is lower; if the operations are complex involving transforming the data, using the data to calculate and insert new values, or reformatting the data, then the risk is higher.

\cbstart The effectiveness of the functional \glspl{mitigation}\index{Mitigation} in reducing impact to the particular \index{Property!Data}data properties needs to be determined. For example, a strong checksum may be very effective at detecting unwanted change and therefore lower the \index{Assurance Level!Software}\gls{software assurance level} (from the perspective of data-related requirements). However, a checksum may not help at all if the issue is one of timely message delivery. More \gls{information} on the use of checksums in the aviation domain is available in \cite{citation:koopman2015selection}; this \gls{information} is likely to be applicable to other domains as well\cbend.

\clearpage %Manual page break
\subsection{Evaluate and \glsfmttext{treat} Risks}
\label{bkm:EvaluateAndTreat}
\subsubsection{Risk \index{Treatment!Risk}\Glsfmttext{treatment}}
There is a range of approaches that could be used to \gls{treat} data-related risks. One option might be to redesign part of a system, either to remove the risk or to incorporate safety devices. Alternatively, ways of mitigating (or, more generally, treating) the risk could be devised. Another option could be to conduct further analysis, for example to better understand the likelihood of a risk occurring. In extreme cases, risk evaluation may lead to a recommendation to cancel a project.

It is apparent that some of these approaches involve repeating activities (or part of activities) discussed in earlier sections of this document. This type of repetition is to be expected given the iterative nature of risk management.

Discussion is an important part of risk evaluation, allowing a variety of different perspectives to be brought to bear. Documentation is also important, partly to allow these discussions to occur on an even footing and partly to ensure that decisions and supporting rationale are recorded.

\subsubsection{Mitigating Data Safety Risks}\index{Mitigation|textbf}
A range of methods and approaches can be used to mitigate the identified data safety risks. Since \gls{mitigation}\index{Mitigation} can be a complex process, requiring collaboration with all system engineering elements, a collection of high-level \gls{mitigation} measures is provided. These may particularly assist those attempting to explain the process to non-practitioners or those conducting assessments in less regulated environments. \cbstart These high-level \gls{mitigation} measures may prove sufficient for practitioners assessing systems which do not have a high safety criticality\cbend.

For practitioners conducting assessments in highly regulated environments, or for highly safety-critical systems, \cbstart appropriate\cbend\ \gls{mitigation}\index{Mitigation} measures should be derived from the high-level table. To assist these practitioners, suggested methods and approaches are provided in a series of more detailed tables. These methods and approaches have been developed through cross-industry collaboration, but they may not be complete, especially for different types of system. 

The practitioner should always consider whether the \gls{mitigation}\index{Mitigation} measures used to mitigate the data safety risks are sufficient for their purposes. In highly safety-critical systems, each data safety risk can be linked to a system-level \cbstart hazard\cbend. Each hazard \cbstart\ should be\cbend\ tracked in accordance with the existing system safety method, and \glspl{mitigation} \cbstart\ should be reviewed for their feasibility, potential to introduce new or amended hazards, and effectiveness\cbend.

\paragraph{High-level \glsfmttext{mitigation} measures}
\autoref{tab:HighLevelMitigations} presents a number of generally applicable \gls{mitigation} measures.
Each of these \gls{mitigation} measures should be reviewed to establish whether it is relevant to the system under assessment.

For each \index{Assurance Level!Data}\gls{dsal}, the tables indicate whether the method / approach is:
\begin{itemize}
  \item Highly recommended (HR);
  \item Recommended (R); or
  \item \cbstart Neither recommended nor not recommended\cbend\ (-).
\end{itemize}

\begin{longtable}%
  {%
    |C{\dsiwgColumnWidth{0.08}}|L{\dsiwgColumnWidth{0.22}}|C{\dsiwgColumnWidth{0.05}}|C{\dsiwgColumnWidth{0.05}}%
    |C{\dsiwgColumnWidth{0.05}}|C{\dsiwgColumnWidth{0.05}}|L{\dsiwgColumnWidth{0.5}}|%
  }%
  \caption{High-level \glsfmttext{mitigation} measures}\index{Mitigation}
  \label{tab:HighLevelMitigations}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}\index{Assurance Level!Data}}}\index{Assurance Level!Data} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColourCX{Ref}} & \multirow{-2}*{\TableHeadColour{\Glsfmttext{mitigation} Measure}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & \multirow{-2}*{\TableHeadColour{Example(s)}}\\\hline
  \hline
  \endfirsthead
    \caption[]{High-level mitigation measures (continued)}\index{Mitigation}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}\index{Assurance Level!Data}}}\index{Assurance Level!Data} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColourCX{Ref}} & \multirow{-2}*{\TableHeadColour{Mitigation Measure}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & \multirow{-2}*{\TableHeadColour{Example(s)}}\\\hline
  \hline
  \endhead
    \multicolumn{7}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  M.01 & %
    Documentation of data context and suitability for use & %
    HR & HR & HR & HR & %
    Data flow diagram to document and agree how data is handled in the system, recording the impact of design decisions on the data aspects of the safety case\\%
    \hline
  M.02 & %
    Definition of \index{Data!Owner}data ownership through the data lifecycle\index{Lifecycle!Data} in the system & %
    R & R & HR & HR & %
    Governance model, \gls{icd}\index{Interface!Control Document}\\%
    \hline
  M.03 & %
    Definition and \gls{traceability} of data requirements & %
    HR & HR & HR & HR & %
    Requirements management, use of test data / test cases\\
    \hline
  M.04 & %
    Recorded trustability of the data source(s) & %
    R & R & HR & HR & %
    Source of the data is trusted (with trusted to be defined in detail for the system), or there are multiple sources of data which are correlated\\%
    \hline
  M.05 & %
    Editing limitations & %
    R & R & HR & HR & %
    Encapsulation%
    \footnote{Sometimes referred to as ``data hiding'', encapsulation hides the physical representation of data.}
    of data, access limitations\\%
    \hline
  M.06 & %
    Diverse and / or redundant manipulation of data & %
    R & R & HR & HR & %
    Data partitioning separation of data that is managed differently (architectural decisions)\\%
    \hline
  M.07 & %
    Automatic system checking functionality &
    -  & R & HR & HR & %
    \Gls{bit}, heartbeat functionality\\%
    \hline
  M.08 & %
    Monitored, controlled, or redundant manipulation of data & %
    - & - & R & HR & %
    Redundant channels processing the data as hot standby\\
    \hline
  M.09 & %
    Diverse and / or redundant storage of data & %
    R & R & HR & HR & %
    Redundant storage of data, multiple different media types used to back up the data\\
    \hline
  M.10 & %
    Data recovery mechanisms &
    R & R & HR & HR & %
    Backward recovery, error correcting codes\\
    \hline
  M.11 & %
    Tracking of data & %
    R & R & HR & HR & %
    Digital signatures, sequence numbers, logging of data processing events, using \gls{metadata}, configuration management\\
    \hline
  M.12 & %
    Recorded derivation of test data & %
    R & R & HR & HR & %
    Test data derived from an established system and supported by field evidence, or from another `trusted' source\\
    \hline
  M.13 & %
    Documented compliance against the data requirements & %
    HR & HR & HR & HR &
    Use of test data / test cases\\
    \hline
\end{longtable}

\paragraph{Detailed methods and approaches}
\label{bkm:DetailedMethods}
The following tables detail methods and approaches which may be used by practitioners conducting \index{Safety Assessment}safety assessments. The tables map the methods and approaches to data categories. \cbstart\ These data categories are abbreviated using the scheme shown in
\autoref{tab:DataCategoryAbbreviations}\cbend.

\cbstart The\cbend\ five data categories\index{Category!Data} presented in \autoref{tab:DataCategoryAbbreviations} are a subset of those presented in \autoref{tab:CategoriesShort}, which presents a comprehensive list of data categories\index{Category!Data}. The five presented in \autoref{tab:DataCategoryAbbreviations} have been used to populate the tables \cbstart\ used\cbend\ for the selection of methods and approaches. \cbstart Users of the guidance are also encouraged to add to this table as part of the customisation process associated with their own organizations or projects\cbend.

\begin{longtable}{|L{\dsiwgColumnWidth{0.2}}|C{\dsiwgColumnWidth{0.2}}|}
  \caption{Data category\index{Category!Data} abbreviations}
  \label{tab:DataCategoryAbbreviations}
  \\\hline
  \TableHeadColour{Data Category} & \TableHeadColourCX{Abbreviation}\\
  \hline
  \endfirsthead
    \caption[]{Data category abbreviations (continued)}
  \\\hline
  \TableHeadColour{Data Category} & \TableHeadColourCX{Abbreviation}\\
  \hline
  \endhead
    \multicolumn{2}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  \Gls{verification}\index{Verification Data} & V\\\hline
  Infrastructure\index{Infrastructure Data} & I\\\hline
  Dynamic\index{Dynamic Data} & D\\\hline
  Performance\index{Performance Data} & P\\\hline
  Justification\index{Justification Data} & J\\\hline
\end{longtable}

The tables also map the methods and approaches to the \index{Property!Data}\glspl{data property}. \cbstart The\cbend\ properties
which were defined in \autoref{tab:PropertiesOfData} have been assigned abbreviations\cbstart, shown in that table.\cbend

\cbstart These\cbend\ detailed methods and approaches tables have been organized into eight, loosely-defined categories:
\begin{itemize}
  \item System design\index{Category!Approach!System Design};
  \item Data design\index{Category!Approach!Data Design};
  \item Data implementation\index{Category!Approach!Data Implementation};
  \item Data migration\index{Category!Approach!Data Migration};
  \item Data testing\index{Category!Approach!Data Testing};
  \item Test data\index{Category!Approach!Test};
  \item Media -- paper\index{Category!Approach!Media -- Paper}; and 
  \item Media -- electronic\index{Category!Approach!Media -- Electronic}.
\end{itemize}

The method for using these tables when considering any given \index{Artefact, Data}\gls{data artefact}, is:
\begin{itemize}
    \item Determine the \gls{dsal}\index{Assurance Level!Data} applicable to the \index{Artefact, Data}\cbstart\gls{data artefact}\cbend, using \autoref{tab:DSAL-risk-matrix} in association with \autoref{tab:Likelihood} and \autoref{tab:Severity}.
    \item Determine the data category\index{Category!Data}, using the abbreviations in \autoref{tab:DataCategoryAbbreviations}.
    \item Determine the list of applicable \index{Property!Data}\glspl{data property}, using the abbreviations in \autoref{tab:PropertiesOfData}. This will generally provide a list of several applicable abbreviations.
\end{itemize}

Then consider each row in each table (or each table that you wish to use for this assessment). For each row, if:
\begin{itemize}
    \item the data category\index{Category!Data} matches the data category\index{Category!Data} for this \index{Artefact, Data}\cbstart\gls{data artefact}\cbend; and
    \item at least one of the \index{Property!Data}\glspl{data property} listed in that row matches a \index{Property!Data}\gls{data property} for the \cbstart\gls{data artefact}\cbend 
\end{itemize}
then the row is likely to be applicable to the \index{Artefact, Data}\cbstart\gls{data artefact}\cbend. The result for that row is therefore found from the \gls{dsal}\index{Assurance Level!Data} column, since if:
\begin{itemize}
    \item The relevant \gls{dsal} entry is ``HR'', then use of the technique on this row is highly recommended.
    \item The relevant \gls{dsal} entry is ``R'', then use of the technique is recommended.
    \item The relevant \gls{dsal} entry is ``-'', then the technique should be considered, as it may be relevant in certain application domains, but \cbstart generic guidance would not be appropriate for specific contexts\cbend.
\end{itemize}

To give a specific example, consider the row corresponding to the first technique in \autoref{tab:MethodsSystemDesign}. This technique will apply to \index{Artefact, Data}\glspl{data artefact} where:
\begin{itemize}
    \item The data category\index{Dynamic Data} is ``dynamic'' (``D'' from \autoref{tab:DataCategoryAbbreviations}) and
    \item The \index{Artefact, Data}\gls{data artefact} holds one or more of the \index{Integrity Property}properties \index{Integrity Property}\gls{integrity}, \index{Completeness!Property}\gls{completeness} or \gls{verifiability}\index{Verifiability Property} (``I'', ``C'' or ``V'' from \autoref{tab:PropertiesOfData}).
\end{itemize}
In such a case, the technique would be highly recommended if the \index{Artefact, Data}\gls{data artefact} were of \gls{dsal}\index{Assurance Level!Data} 3 or 4, recommended if the \gls{dsal} were 2, or should merely be considered if the \gls{dsal} were 1.

Many dots have been placed in the table to indicate data categories\index{Category!Data} and \index{Property!Data}data properties which are not applicable to the technique under consideration. The dots enable the tables to be assessed very quickly, as they enable the letters representing specific Data categories\index{Category!Data} and \index{Property!Data}\glspl{data property} to always be presented in the same position within the table. For example, the \index{Property!Data}\gls{data property} ``\gls{verifiability}''\index{Verifiability Property} (``V'' from \autoref{tab:PropertiesOfData} can easily be seen to appear against the first two techniques of \autoref{tab:MethodsSystemDesign}, whereas it does not appear in the next seven techniques. This can be seen without actually reading the text, but merely looking at the pattern presented by the letters and dots. 

Within each table, the ``Serial'' column lists a unique serial number for each technique. The serial numbers simply provide a unique reference which aligns with those implemented within the toolset.

\paragraph{System Design}

% This next table breaks the rules slightly, with a width of 1.005, as opensans was updated in TeXlive 2019
% Breaking the rules was the only way to keep the page layout in 3.3 aligned with that in 3.2. 
\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.27}}|C{\dsiwgColumnWidth{0.24}}|%Notes, Properties
  }%
  \caption{\Glsfmttext{mitigation} methods: system design}\index{Mitigation}
  \label{tab:MethodsSystemDesign}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
    \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
    \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
    \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Gglsfmttext{data property}}}\\\hline
  \hline
  \endfirsthead
  \caption[]{\Glsfmttext{mitigation} methods: system design (continued)}\index{Mitigation}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
    \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category} & %
    \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
    \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}\Glsfmttext{data property}}}\\\hline
  \hline
  \endhead
    \multicolumn{9}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  SD.01 & \gls{bit} / \gls{bite} &  \usefont{T1}{cmtt}{m}{n}{..D..} & - & R & HR & HR & Application tests the data (e.g., at start-up or when requested by an operator). &  \usefont{T1}{cmtt}{m}{n}{IC.......V.............}\\
  \hline
  SD.02 & Cyclic / continuous \gls{bit} & \dsiwgTextTT{..D..} & - & - & R & HR & Application applies tests to the data it is processing continuously (e.g., for a live data stream) or periodically (e.g., every nth message, every hour). & \dsiwgTextTT{IC.Y.....VL............}\\
  \hline
  SD.03 & Backward recovery & \dsiwgTextTT{..D..} & R & R & HR & HR & If a fault in data has been detected, the system resets to an earlier internal \gls{dataset}, which has been proven consistent. & \dsiwgTextTT{IC.....................}\\
  \hline
  SD.04 & Parity checks & \dsiwgTextTT{..D..} & R & R & HR & HR & Within data, e.g., Hamming codes, Reed-Solomon, Hagelbarger. & \dsiwgTextTT{I......................}\\
  \hline
  SD.05 & Automatic error correction & \dsiwgTextTT{..D..} & R & R & HR & HR & Detected errors are corrected automatically. & \dsiwgTextTT{IC.....................}\\
  \hline
  SD.06 & Checksums / \glspl{crc} / Hashes & \dsiwgTextTT{..D..} & - & R & HR & HR & Digests of \glspl{dataset} are produced, included with the \gls{dataset} and checked to provide confidence that the data is unaltered. & \dsiwgTextTT{IC..................G..}\\
  \hline
  SD.07 & Digital signatures & \dsiwgTextTT{..D..} & - & R & HR & HR & For non-repudiation and \index{Integrity Property}\gls{integrity} of data. & \dsiwgTextTT{I......T......U.....G..}\\
  \hline
  SD.08 & Sequence numbers & \dsiwgTextTT{..D..} & R & R & HR & HR & Data bears sequence numbers so the \index{Integrity Property}\gls{integrity} of a data stream can be checked (e.g., monotonic increase, duplicate detection). & \dsiwgTextTT{ICN.........PQ.........}\\
  \hline
  SD.09 & Automatic repeat request & \dsiwgTextTT{..D..} & R & R & HR & HR & \Gls{arq} to repeat transmission of data which has not been received correctly. & \dsiwgTextTT{IC.Y................G..}\\
  \hline
  SD.10 & Auditing facilities & \dsiwgTextTT{..DP.} & - & R & HR & HR & Changes to \index{Property!Data}\glspl{data property} are audited so the before and after values are recorded and also other related \gls{information} such as the author and the time of the change. & \dsiwgTextTT{.......T.V.......H...ZX}\\
  \hline
  SD.11 & Logging facilities & \dsiwgTextTT{..DP.} & R & R & HR & HR & Data processing events are logged to allow support staff to monitor the health of the system and provide diagnostic \gls{information}. & \dsiwgTextTT{.......T.........H...ZX}\\
  \hline
  SD.12 & Encapsulation & \dsiwgTextTT{..D..} & R & R & HR & HR & \cbstart Data is hidden\cbend\ so that it is only accessible through well-defined interfaces. & \dsiwgTextTT{..............UB.......}\\
  \hline
  SD.13 & Multiple stores & \dsiwgTextTT{..D..} & - & - & R & HR & The same instance of a \gls{dataset} or \glspl{item data} is stored in multiple locations. & \dsiwgTextTT{...............B.H.....}\\
  \hline
  SD.14 & Homogeneous redundancy & \dsiwgTextTT{..D..} & - & - & R & HR & Data is processed using homogeneous redundant channels; detected faults in data of one channel cause processing to switch to another channel. & \dsiwgTextTT{IC.Y....M..............}\\
  \hline
  SD.15 & Heterogeneous redundancy & \dsiwgTextTT{..D..} & - & - & R & HR & Data is processed using heterogeneous redundant channels; detected faults in data of one channel cause processing to switch to another channel. & \dsiwgTextTT{IC.Y....M..............}\\
  \hline
  SD.16 & Data \index{Integrity Property}\gls{integrity} sampling & \dsiwgTextTT{..D..} & HR & HR & R & R & The \index{Integrity Property}\gls{integrity} of subsets of data is periodically checked, in accordance with a given selection criteria (e.g., random, critical records). & \dsiwgTextTT{IC..O.....L............}\\
  \hline
  SD.17 &\cbstart\ Credibility\cbend\ / reasonability checks & \dsiwgTextTT{V.D..} & R & R & HR & HR & Dedicated processing is implemented to check that data is within reasonable tolerances and / or logically / semantically consistent (e.g., range checks, date checks, record counts, record sizes, special values - \gls{nan}). & \dsiwgTextTT{I...O...............G..}\\
  \hline
  SD.18 & Data correlation & \dsiwgTextTT{..D..} & R & R & HR & HR & Data from a number of sources exists to permit a cross-correlation of the data supplied from one source (the master) with other sources. & \dsiwgTextTT{ICNY...................}\\
  \hline
  SD.19 & Data partitioning & \dsiwgTextTT{..D..} & R & R & HR & HR & To separate data that is managed differently, creating independence so that a whole \gls{dataset} does not require \gls{validation} after a change. & \dsiwgTextTT{...............B.......}\\
  \hline
  SD.20 & Syntax checks & \dsiwgTextTT{VID..} & R & R & HR & HR & Semantic checking of data values and sequences based on defined rule sets. & \dsiwgTextTT{I.N.O...............G..}\\
  \hline
  SD.21 & Feedback testing & \dsiwgTextTT{..D..} & HR & HR & R & R & To check output data by comparing it with the input source. & \dsiwgTextTT{IC.Y...T.V..........G..}\\
  \hline
  SD.22 & \Gls{information} redundancy & \dsiwgTextTT{..D..} & HR & HR & R & R & Additional redundant \gls{information} is supplied from diverse sources. \cbstart\ The diverse sources can be checked against each other\cbend. & \dsiwgTextTT{IC..................G..}\\
  \hline
  SD.23 & Reverse translation & \dsiwgTextTT{..D..} & - & R & HR & HR & \cbstart\ Verifying\cbend\ data output of a process is correct, by attempting to create the source data from the output data and comparing this with the original source. & \dsiwgTextTT{IC.Y...T..............X}\\
  \hline
  SD.24 & \Gls{metadata} & \dsiwgTextTT{..DP.} & - & R & HR & HR & Auditable data are sent with the data that is about the data (e.g., source, issue state, expiry date). & \dsiwgTextTT{..N....T.V..PQ....E..ZX}\\
  \hline
\end{longtable}

\clearpage% Avoids having a single row of the table on the first page 
\paragraph{Data Design}
\autoref{tab:MethodsDataDesign} addresses design aspects, including the construction of data storage structures and methods.
\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.25}}|C{\dsiwgColumnWidth{0.26}}|%Notes, Properties
  }%
  \caption{\Glsfmttext{mitigation} methods: data design}\index{Mitigation}
  \label{tab:MethodsDataDesign}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
    \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
    \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
    \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endfirsthead
   \caption[]{\Glsfmttext{mitigation} methods: data design (continued)}\index{Mitigation}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
    \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{\index{Category!Data}} & %
    \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
    \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endhead
    \multicolumn{9}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  DD.01 & Governance model & \dsiwgTextTT{VI..J} & R & R & HR & HR & A governance model is established that defines, e.g., \index{Data!Owner}data ownership, processing roles and responsibilities, processing authorizations and permissions. & \dsiwgTextTT{I....A.T......U.S..D..X}\\
  \hline
  DD.02 & Data process definition & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Documented and agreed process definitions for how data is handled. & \dsiwgTextTT{.......T......U.....G.X}\\
  \hline
  DD.03 & Data flow diagram & \dsiwgTextTT{VIDPJ} & HR & HR & HR & HR & To describe the data flow in a diagrammatic form. & \dsiwgTextTT{..............U......Z.}\\
  \hline
  DD.04 & Data model & \dsiwgTextTT{VIDPJ} & HR & HR & HR & HR & To articulate how data is organized. & \dsiwgTextTT{..N.O................ZX}\\
  \hline
  DD.05 & Client sign-off & \dsiwgTextTT{VI.PJ} & R & R & HR & HR & Agreement from the client that the system architecture and design are appropriate for the data considered. & \dsiwgTextTT{......R..V.............}\\
  \hline
  DD.06 & \Gls{quality} Correction mechanisms & \dsiwgTextTT{...P.} & - & R & HR & HR &  Design incorporates a \gls{quality} management system. & \dsiwgTextTT{IC.Y...................}\\
  \hline
  DD.07 & Configuration management & \dsiwgTextTT{VIDPJ} & HR & HR & HR & HR & A formal process that controls changes to the data and data model. & \dsiwgTextTT{.......T.........H.....}\\
  \hline
  DD.08 & \Gls{data dictionary} & \dsiwgTextTT{VIDPJ} & HR & HR & HR & HR & A collection of descriptions of the data objects or \cbstart\glspl{item data}\cbend\ in a data model for the benefit of data users. & \dsiwgTextTT{..N.O.R....F.........ZX}\\
  \hline
  DD.09 & Formal methods & \dsiwgTextTT{..D..} & - & R & R & HR &
  To specify data (or data formats) in a precise, mathematical manner. &
  \dsiwgTextTT{.CN.O..T....PQ......GZX}\\
  \hline
\end{longtable}

\clearpage% Avoids having the following title as a widow on the first page
\paragraph{Data \glsfmttext{verification}}
\label{bkm:dataVerification}
A number of issues need to be considered during the implementation phase of a programme, to ensure that at any point in the programme we know how much we can rely upon the data. \autoref{tab:MethodsDataProcedures} addresses those \glspl{mitigation}\index{Mitigation} relevant to this whole programme phase, not just from data capture or generation. It therefore includes aspects of data management, checking and expiry.
\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.25}}|C{\dsiwgColumnWidth{0.26}}|%Notes, Properties
  }%
  \caption{\glsfmttext{mitigation} methods: data \glsfmttext{verification}}\index{Mitigation}
  \label{tab:MethodsDataProcedures}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data}& %
  \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
  \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endfirsthead
  \caption[]{\Glsfmttext{mitigation} methods: data \glsfmttext{verification} (continued)}\index{Mitigation}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
  \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
  \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endhead
    \multicolumn{9}{r}{\sl Continued on next page}
\endfoot
\endlastfoot
  DI.01 & Review / inspection & \dsiwgTextTT{VIDPJ} & HR & HR & HR & HR & Manual review / inspection of data possibly involving data visualization tools. & \dsiwgTextTT{IC..O.....L...........X}\\
  \hline
  DI.02 & Statistics-based sampling & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & More appropriate for real-time large and / or volume data. Could be manual selection, a form of random selection or comparison against statistical norms. & \dsiwgTextTT{I.NY.A...............Z.}\\
  \hline
  DI.03 & Ground-truth check & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Inspection against physical measurements (e.g., lengths, positions, heights) taken in the real world. & \dsiwgTextTT{ICN..AR..V.F..........X}\\
  \hline
  DI.04 & Auditing & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & A period of comprehensive internal and external testing of the \gls{quality} process. & \dsiwgTextTT{ICNYO....V............X}\\
  \hline
  DI.05 & Tracing & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Ability to trace data from source across multiple participants in the data supply chain. & \dsiwgTextTT{.......T.V............X}\\
  \hline
  DI.06 & Defined \gls{verification} frequency & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Data should contain an indicator of how often it should be revalidated against other (e.g., real-world) source. & \dsiwgTextTT{.........V........E....}\\
  \hline
  DI.07 & Defined data lifetime(s) & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & \Gls{information} showing when data \gls{validity} expires. & \dsiwgTextTT{..................E....}\\
  \hline
  DI.08 & \Gls{quality} trend analysis & \dsiwgTextTT{VIDPJ} & - & - & R & HR & Checking that a \gls{dataset} is consistent with a model of the expected data behaviour (e.g., vibration data increases over time). & \dsiwgTextTT{IC.Y.....V.F.........Z.}\\
  \hline
  DI.09 & Authorization & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & A security model is established to control who is authorized to create, view, edit, delete the data. & \dsiwgTextTT{..............UBS..D...}\\
  \hline
  DI.10 & Authentication & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Data is authenticated to validate its provenance. & \dsiwgTextTT{.......T.V............X}\\
  \hline
  DI.11 & Defined confidence / trust levels & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Criteria are established to provide an objective measurement of the confidence or trust in a given \gls{dataset}. & \dsiwgTextTT{IC.Y.....V.F..........X}\\
  \hline
  DI.12 & Independent check & \dsiwgTextTT{VIDPJ} & - & - & R & HR & A separate person or system is used to check the data independently. & \dsiwgTextTT{I........V.............}\\
  \hline
  DI.13 & Update comparison & \dsiwgTextTT{VIDPJ} & - & R & R & HR & Updated data is compared to its previous version (e.g., so the list of changed elements can be compared with a supplier-generated list). & \dsiwgTextTT{.......T.........H..G..}\\
  \hline
\end{longtable}

\clearpage% Avoids having the final row of the table on a page by itself 
\paragraph{Data migration}
\cbstart \autoref{tab:MethodsDataMigration} addresses migration of data from one system to another system.\cbend\

\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.25}}|C{\dsiwgColumnWidth{0.26}}|%Notes, Properties
  }%
  \caption{\Glsfmttext{mitigation} methods: data migration}\index{Mitigation}
  \label{tab:MethodsDataMigration}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
  \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
  \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endfirsthead
  \caption[]{\Glsfmttext{mitigation} methods: data migration (continued)}\index{Mitigation}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
  \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
  \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endhead
  \multicolumn{9}{r}{\sl Continued on next page}
  \endfoot
  \endlastfoot
  DM.01 & Manual load & \dsiwgTextTT{..D..} & R & R & - & - & Data is entered into the system manually relying on human \gls{validation} and \gls{verification}. & \dsiwgTextTT{ICNYOA.....F...........}\\
  \hline
  DM.02 & Dedicated translation and loading platform & \dsiwgTextTT{..D..} & - & R & HR & HR & For example, using mature enterprise migration \gls{cots} products. & \dsiwgTextTT{ICNYOA.T...F...........}\\
  \hline
  DM.03 & Existing / established system transfer & \dsiwgTextTT{..D..} & - & R & HR & HR & Use of an existing / established proven transfer mechanism. & \dsiwgTextTT{ICNYOA.T...F...........}\\
  \hline
  DM.04 & Client supervision & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & The client provides independent supervision of activities checking processes, inputs and outputs at agreed points. & \dsiwgTextTT{ICNYOA.....F...........}\\
  \hline
  DM.05 & Client sign-off & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Formal acceptance of the migrated \glspl{dataset} in the target system. & \dsiwgTextTT{ICNYOA.....F...........}\\
  \hline
  DM.06 & Incremental switch-over & \dsiwgTextTT{..D..} & - & R & HR & HR & Users are incrementally switched over to the new system rather than as a ``big bang''. & \dsiwgTextTT{ICNYOA.....F...........}\\
  \hline
  DM.07 & Parallel load with existing system & \dsiwgTextTT{..D..} & - & R & HR & HR & Parallel running of the new system alongside the existing system with data crosschecks between the two systems. & \dsiwgTextTT{ICNYOA.....F...........}\\
  \hline
  DM.08 & Shadowing & \dsiwgTextTT{..D..} & - & R & HR & HR & Parallel running of the new system alongside the existing system, only data from the existing system is used operationally, with an experienced user crosschecking between the two systems. & \dsiwgTextTT{ICNYOA.....F...........}\\
  \hline
  DM.09 & End-to-end import-export \gls{verification} & \dsiwgTextTT{..D..} & - & R & HR & HR & Data is traced and verified at all stages through the entire end to end migration process. & \dsiwgTextTT{ICNYOA.T...F..........X}\\
  \hline
DM.10&
End-to-end size compare&
\dsiwgTextTT{..D..}&
R&
R&
HR&
HR&
Data is extracted from new or final system and its size or volume compared with original data as input
&
\dsiwgTextTT{IC.Y.....V..........G..}\\\hline
%
DM.11&
End-to-end content compare&
\dsiwgTextTT{..D..}&
R&
R&
HR&
HR&
Data is extracted from new or final system and compared with original data as input, possibly on a sample basis
&
\dsiwgTextTT{ICN....T.V.F...........}\\\hline
%
DM.12&
\Gls{validation} campaign&
\dsiwgTextTT{..D..}&
R&
R&
HR&
HR&
An extensive set of \gls{validation} checks is performed on the migrated data.
&
\dsiwgTextTT{ICNY.....V.............}\\\hline
%
DM.13&
Interpretation check&
\dsiwgTextTT{..D..}&
R&
R&
HR&
HR&
Migrated data is checked for misinterpretation in the new system (e.g. due to units, national, or cultural aspects).
&
\dsiwgTextTT{..N.O....V.F..U......Z.}\\\hline
%
DM.14&
Data cleanse trial&
\dsiwgTextTT{..D..}&
R&
R&
HR&
HR&
Data cleansing is tried on subsets of the data and special cases,
before being applied to the whole set (e.g. removing time-expired, obsolete or repeated data)
&
\dsiwgTextTT{IC................EDG..}\\\hline
%
DM.15&
\Gls{metadata} preservation&
\dsiwgTextTT{..D..}&
- &
- &
R&
R&
Any meta-data as part of the original \gls{dataset} which cannot be incorporated or translated into the new system is preserved
&
\dsiwgTextTT{IC.Y...T.........H...ZX}\\\hline
\end{longtable}

\clearpage% Avoids having The section title as a widow at the bottom of the page 
\paragraph{Data checking}
\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.25}}|C{\dsiwgColumnWidth{0.26}}|%Notes, Properties
  }%
  \caption{\Glsfmttext{mitigation} methods: data checking}\index{Mitigation}
  \label{tab:MethodsDataChecking}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
  \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
  \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endfirsthead
  \caption[]{Mitigation methods: data checking (continued)}\index{Mitigation}
  \\\hline
  \TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
  \TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
  \multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{\index{Category!Data}} & %
  \TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
  \multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
  \hline
  \endhead
    \multicolumn{9}{r}{\sl Continued on next page}
\endfoot
\endlastfoot
  DC.01 & Limited / pre-operational deployment & \dsiwgTextTT{.IDP.} & - & R & HR & HR & A period of monitored operation in a specially chosen environment. & \dsiwgTextTT{ICN..A.....F...........}\\
  \hline
  DC.02 & Client sign-off of data & \dsiwgTextTT{VI.PJ} & - & R & HR & HR & Agreement from the client that the data is appropriate. & \dsiwgTextTT{......R..V.............}\\
  \hline
  DC.03 & Non-critical trialling & \dsiwgTextTT{..D..} & - & R & HR & HR & Monitored operation in an operational, but non-critical, environment. & \dsiwgTextTT{.....A.....F...........}\\
  \hline
  DC.04 & Beta testing & \dsiwgTextTT{V....} & - & R & HR & HR & Testing with a small group of specially chosen users. & \dsiwgTextTT{ICN..A.....F...........}\\
  \hline
  DC.05 & Parallel running & \dsiwgTextTT{.IDP.} & - & R & HR & HR & Running two systems in parallel and crosschecking between them. & \dsiwgTextTT{ICN..A..M..FP..........}\\
  \hline
  DC.06 & Checklists & \dsiwgTextTT{.IDP.} & R & R & HR & HR &
  Using a checklist to verify that system behaviour is correct, prior to use. This approach can also be effective for detecting otherwise dormant failures and reduces time at risk.
  & \dsiwgTextTT{ICN.O....VLFP..........}\\
  \hline
  DC.07 & Widespread distribution to user community & \dsiwgTextTT{.IDP.} & - & R & HR & HR & Large-scale distribution to all users. & \dsiwgTextTT{ICN.OAR.M.LFP..........}\\
  \hline
\end{longtable}

\clearpage %Manual page break
\paragraph{Test data}
\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.25}}|C{\dsiwgColumnWidth{0.26}}|%Notes, Properties
  }%
  \caption{\Glsfmttext{mitigation} methods: test data}\index{Mitigation}
  \label{tab:MethodsTestData}
  \\\hline
\TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
\TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
\multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
\TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
\multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
\hline
\endfirsthead
  \caption[]{\Glsfmttext{mitigation} methods: test data (continued)}\index{Mitigation}
\\\hline
\TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
\TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
\multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
\TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
\multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
\hline
\endhead
    \multicolumn{9}{r}{\sl Continued on next page}
\endfoot
\endlastfoot
  TD.01 & Using informal / ad-hoc means & \dsiwgTextTT{V....} & R & R & - & - & Data is generated by simple means (e.g, spreadsheets, scripts, basic assumptions). There is no formal checking or review of the method of generation. & \dsiwgTextTT{ICNY.A.....F...........}\\
  \hline
  TD.02 & Using \cbstart generic \cbend testbed & \dsiwgTextTT{V....} & - & R & HR & HR & \cbstart A testbed \cbend is a good way to produce test data. It may require configuration and \gls{tailoring}\index{Tailoring} for the particular application, and this configuration should be managed. & \dsiwgTextTT{ICNY.A.....F........G..}\\
  \hline
  TD.03 & Using simulator & \dsiwgTextTT{V....} & - & R & HR & HR & Simulators (software or hardware) may be able to produce very good test data, obviously depending on how close and detailed a simulation they can achieve. & \dsiwgTextTT{ICNYOAR....F........G..}\\
  \hline
  TD.04 & Using prototype & \dsiwgTextTT{V....} & - & R & HR & HR & Prototypes are often a good way of generating test data for the real system. However they may not produce data with the appropriate range, \index{Accuracy Property}\gls{accuracy} or precision. & \dsiwgTextTT{ICNY.A.....F........G..}\\
  \hline
  TD.05 & Using manual means & \dsiwgTextTT{V....} & R & R & - & - & Simple test data can be produced by manual means, although this may be prone to human error. & \dsiwgTextTT{ICNY.A.....F........G..}\\
  \hline
  TD.06 & Using dedicated platform & \dsiwgTextTT{V....} & - & R & HR & HR & For complex and time-critical systems a dedicated test platform is required which can produce realistic test data for all interfaces and inputs. & \dsiwgTextTT{ICNY.AR..V.FPQ.........}\\
  \hline
  TD.07 & Using existing / established system & \dsiwgTextTT{V....} & - & R & HR & HR & Where a new system replaces an old one, then data can often be extracted from the old system to test the new one. Data formats may change so translation may be required. & \dsiwgTextTT{ICNYOAR.MV.FPQU.....G..}\\
  \hline
  TD.08 & Using initial runs of new system & \dsiwgTextTT{V....} & R & R & R & R & This method is often used where the system is breaking new ground and there is no prototype or legacy system to produce test data. Initial operations may differ from eventual usage, so test data must evolve. & \dsiwgTextTT{ICNYOAR.MV.FPQ.........}\\
  \hline
  TD.09 & Derived from real data & \dsiwgTextTT{V....} & R & R & HR & HR & Where real data is available this is usually a good basis for generating test data (e.g., by modification to increase the test space coverage). & \dsiwgTextTT{ICNY.A.....F........G.X}\\
  \hline
  TD.10 & Statistical profiling post-production & \dsiwgTextTT{V....} & - & - & R & HR & If a statistical analysis of the data can be produced then greater confidence in the quality of the test data can be obtained. & \dsiwgTextTT{ICNY.A...V.F..........X}\\
  \hline
  TD.11 & Produced by client & \dsiwgTextTT{V....} & R & R & R & HR & Ideally the client is involved in producing or at least checking the test data. & \dsiwgTextTT{ICNY.A...V.F........G..}\\
  \hline
  TD.12 & Client sign-off & \dsiwgTextTT{V....} & R & R & HR & HR & Where possible, the client should formally agree and sign off the test data as appropriate. & \dsiwgTextTT{ICNY.A...V.F..........X}\\
  \hline
  TD.13 & Error seeding & \dsiwgTextTT{V....} & R & R & HR & HR & This is where errors are deliberately inserted into the \gls{dataset} to demonstrate the effectiveness of data \gls{validation}. & \dsiwgTextTT{ICNYOAR.MV.F........G..}\\
  \hline
  TD.14 & Data reuse & \dsiwgTextTT{V....} & R & R & HR & HR & Reusing data for one project that was created and thoroughly assured for another project. This can be effective but the read-across should be established. & \dsiwgTextTT{ICNY.A.....F........G.X}\\
  \hline
  TD.15 & Feedback testing & \dsiwgTextTT{V....} & R & R & R & R & To check output data by comparing it with the input source. & \dsiwgTextTT{ICNY.A.....F...........}\\
  \hline
\end{longtable}

\clearpage% Avoids having a single row of the table on the first page 
\paragraph{Media -- Paper}
\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.25}}|C{\dsiwgColumnWidth{0.26}}|%Notes, Properties
  }%
  \caption{\Glsfmttext{mitigation} methods: data media handling -- paper / physical storage}\index{Mitigation}
  \label{tab:MethodsDataMediaPhysical}
  \\\hline
\TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
\TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
\multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
\TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
\multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
\hline
\endfirsthead
  \caption[]{Mitigation methods: data media handling -- paper / physical storage (continued)}\index{Mitigation}
\\\hline
\TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
\TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
\multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
\TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
\multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
\hline
\endhead
    \multicolumn{9}{r}{\sl Continued on next page}
\endfoot
\endlastfoot
  MP.01 & Photographic copies & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Photocopy and store separately. & \dsiwgTextTT{.C.............B.H.....}\\
  \hline
  MP.02 & Scan to electronic format & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Retain both paper and electronic copies. & \dsiwgTextTT{.C.............B.H.....}\\
  \hline
  MP.03 & Copies held at different locations & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Meaning of ``different'' depends on data \gls{criticality} and similarity of location-based risks. & \dsiwgTextTT{.........VL....B.......}\\
  \hline
  MP.04 & Limited access & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Control (e.g., by procedure) who can access the data. & \dsiwgTextTT{..............U........}\\
  \hline
  MP.05 & Secure storage & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Physical measures to prevent unauthorized access. & \dsiwgTextTT{..............U........}\\
  \hline
  MP.06 & Manual inspection & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Used to check data when generated and periodically thereafter. & \dsiwgTextTT{IC.....................}\\
  \hline
  MP.07 & Suitable physical environment & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & For example, prevent water ingress, control temperature. & \dsiwgTextTT{I.........L.......E....}\\
  \hline
  MP.08 & Defined handling procedures & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & To ensure that changes to the data can be attributed. & \dsiwgTextTT{I.............UB.H.....}\\
  \hline
  MP.09 & Repair / restoration programme & \dsiwgTextTT{VIDPJ} & - & - & R & HR & To protect against degradation and to ensure \index{Availability Property}\gls{availability}. & \dsiwgTextTT{I.........L............}\\
  \hline
  MP.10 & Indexing / cataloguing & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & To support efficient\cbstart\ availability\cbend. & \dsiwgTextTT{..........L............}\\
  \hline
  MP.11 & Lifetime planning & \dsiwgTextTT{VIDPJ} & - & - & R & HR & For example, to avoid gradual quality reduction by repeatedly ``copying a copy''. & \dsiwgTextTT{..................ED...}\\
  \hline
\end{longtable}

\clearpage
\paragraph{Media -- electronic}
\begin{longtable}
  {%
    |C{\dsiwgColumnWidth{0.07}}%Index
    |L{\dsiwgColumnWidth{0.16}}|C{\dsiwgColumnWidth{0.105}}%Technique, category
    |C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}|C{\dsiwgColumnWidth{0.04}}%DSALs
    |L{\dsiwgColumnWidth{0.25}}|C{\dsiwgColumnWidth{0.26}}|%Notes, Properties
  }%
  \caption{\Glsfmttext{mitigation} methods: data media handling -- electronic storage}\index{Mitigation}
  \label{tab:MethodsDataMediaElectronic}
  \\\hline
\TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
\TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
\multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
\TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
\multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
\hline
\endfirsthead
  \caption[]{\Glsfmttext{mitigation} methods: data media handling -- electronic storage (continued)}\index{Mitigation}
\\\hline
\TableHeadColour{} & \TableHeadColour{} & \TableHeadColour{Data} & \multicolumn{4}{c|}{\TableHeadColourCX{\glsfmtshort{dsal}}}\index{Assurance Level!Data} & %
\TableHeadColour{} & \TableHeadColour{}\\\cline{3-6}
\multirow{-2}*{\TableHeadColour{Serial}} & \multirow{-2}*{\TableHeadColourCX{Technique}} & \TableHeadColour{Category\index{Category!Data}} & %
\TableHeadColourCX{1} & \TableHeadColourCX{2} & \TableHeadColourCX{3} & \TableHeadColourCX{4} & %
\multirow{-2}*{\TableHeadColour{Notes}} & \multirow{-2}*{\TableHeadColour{\index{Property!Data}Data Property}}\\\hline
\hline
\endhead
    \multicolumn{9}{r}{\sl Continued on next page}
\endfoot
\endlastfoot
  ME.01 & Regular refresh / rewrite & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Of magnetic media or flash memory. & \dsiwgTextTT{I.................E....}\\
  \hline
  ME.02 & Suitable physical environment & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Store media in a clean, low-humidity environment at a steady temperature, cool but not cold. & \dsiwgTextTT{I.........L.......E....}\\
  \hline
  ME.03 & Copies at different locations & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Physically separate to cover natural disasters, accidental or malicious damage. & \dsiwgTextTT{.........VL....B.......}\\
  \hline
  ME.04 & Backups / \cbstart\ duplicates\cbend& \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Backups are essential. Frequency of backup depends on rate of change. The number of generations to keep relates to the impact of data loss. & \dsiwgTextTT{..........L............}\\
  \hline
  ME.05 & Sample restores & \dsiwgTextTT{VIDPJ} & R & R & HR & HR & Sample restores should be performed at intervals to ensure that the backups are readable and retrievable. & \dsiwgTextTT{..........L............}\\
  \hline
  ME.06 & Multiple copies & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & At least two backups should be kept, preferably in diverse formats. & \dsiwgTextTT{.........VL............}\\
  \hline
  ME.07 & Copy to latest media format & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Anticipate obsolescence and plan a smooth transition to new technologies. & \dsiwgTextTT{..........L............}\\
  \hline
  ME.08 & Media physically secured & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Access to, and removal of, media should be controlled by suitable procedures. Access permissions should be reviewed at intervals. & \dsiwgTextTT{.......T......U..H.....}\\
  \hline
  ME.09 & Resilient / redundant format & \dsiwgTextTT{VIDPJ} & - & - & R & HR & This may involve less use of compression, use of error detection and correction protocols, and (at the highest level) two or more redundant data servers. & \dsiwgTextTT{IC........L............}\\
  \hline
  ME.10 & Long-lifetime format & \dsiwgTextTT{VIDPJ} & - & - & R & HR & The best formats should be adopted where available. & \dsiwgTextTT{..........L.......E....}\\
  \hline
  ME.11 & Easily translatable / convertible format & \dsiwgTextTT{VIDPJ} & - & - & R & HR & Adopt widely-used, well-documented, general-purpose formats in preference to specialist proprietary formats. & \dsiwgTextTT{....O.....L............}\\
  \hline
  ME.12 & Copy to cloud storage & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Must specify whether a private cloud or a public cloud shall be used. Cloud storage may not be suitable for highly confidential data. & \dsiwgTextTT{..........L............}\\
  \hline
  ME.13 & Copy to archiving organization & \dsiwgTextTT{VIDPJ} & - & R & HR & HR & Consider the required level of data \index{Integrity Property}\gls{integrity} and \gls{confidentiality}; also, the \index{Integrity Property}\gls{integrity} and long-term viability of the archiving organization, and plans in case it ceases to function. & \dsiwgTextTT{..........L............}\\
  \hline
\end{longtable}

\paragraph{Recording the data safety risk \glsfmttext{mitigation}}\index{Mitigation}
The \gls{dsmp} can be used to document:
\begin{itemize}
  \item the tables of \gls{mitigation} measures (or methods and approaches) used for the system, context, and planned implementation under assessment;
  \item any specific \gls{mitigation} measures identified for the system and their source / justification;
  \item planned compliance with the tables; and
  \item confirmation that the \gls{mitigation} measures are sufficiently complete and consistent.
\end{itemize}  
The overall safety justification for the given \cbstart project, service, or operational context must then provide evidence of compliance with\cbend\ the plan.
